3-24. What is the best data structure for maintaining URLs that have been visited by a Web crawler? Give an algorithm to test whether a given URL has already been visited, optimizing both space and time.

**Solution**

The potential problem space for this problem is very huge so we need an efficient data structure that can efficiently store information.

A simple solution would be to create a hashtable mapping website host urls to an array of all crawled paths for that host name. This might not scale well if you have to crawl a trillion web sites though.

Another approach would use the [bloom filter](https://en.wikipedia.org/wiki/Bloom_filter); although it can give a false positive, there are ways to minimize this.